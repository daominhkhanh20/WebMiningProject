{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'assets/report/ann_report.pk', 'rb') as fin:\n",
    "    ann_report = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ls = ['ann_report_over_sampling','ann_report']\n",
    "for model in model_ls:\n",
    "    title = []\n",
    "    for key in ann_report:\n",
    "        if 'acc' in key:\n",
    "            plt.plot(ann_report[key])\n",
    "            title.append(key)\n",
    "    plt.legend(title)\n",
    "    plt.title('Ann model')\n",
    "    \n",
    "    # plt.show()\n",
    "    plt.savefig(f'assets/report/{model}_acc.png')\n",
    "    plt.close()\n",
    "    title = []\n",
    "    for key in ann_report:\n",
    "        if 'acc' not in key:\n",
    "            plt.plot(ann_report[key])\n",
    "            title.append(key)\n",
    "    plt.legend(title)\n",
    "    plt.title('Ann model')\n",
    "    plt.savefig(f'assets/report/{model}_loss.png')\n",
    "    # plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = ['ann_config_architecture_over_sampling','ann_config_architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_labels = {'negative':0,'neutral':1,'positive':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_labels = {0:'negative',1:'neutral',2:'positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels_truth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11528/114907556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'assets/models/{conf}.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{conf}_labels_truth'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels_truth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{conf}_labels_pred'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{conf}_labels_truth'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{conf}_labels_truth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'labels_truth'"
     ]
    }
   ],
   "source": [
    "for conf in conf_list:\n",
    "    f = open(f'assets/models/{conf}.json')\n",
    "    data = json.load(f)\n",
    "    df[f'{conf}_labels_truth'] = data['labels_truth']\n",
    "    df[f'{conf}_labels_pred']  = data['labels_pred']\n",
    "    df[f'{conf}_labels_truth'] = df[f'{conf}_labels_truth'].map(inv_labels)\n",
    "    df[f'{conf}_labels_pred'] = df[f'{conf}_labels_pred'].map(inv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_config_architecture_over_sampling_labels_truth</th>\n",
       "      <th>ann_config_architecture_over_sampling_labels_pred</th>\n",
       "      <th>ann_config_architecture_labels_truth</th>\n",
       "      <th>ann_config_architecture_labels_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3166 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ann_config_architecture_over_sampling_labels_truth  \\\n",
       "0                                              negative   \n",
       "1                                              positive   \n",
       "2                                              positive   \n",
       "3                                              positive   \n",
       "4                                              positive   \n",
       "...                                                 ...   \n",
       "3161                                            neutral   \n",
       "3162                                           negative   \n",
       "3163                                           positive   \n",
       "3164                                           negative   \n",
       "3165                                           negative   \n",
       "\n",
       "     ann_config_architecture_over_sampling_labels_pred  \\\n",
       "0                                             negative   \n",
       "1                                             positive   \n",
       "2                                             positive   \n",
       "3                                             negative   \n",
       "4                                             negative   \n",
       "...                                                ...   \n",
       "3161                                          positive   \n",
       "3162                                          negative   \n",
       "3163                                          positive   \n",
       "3164                                          negative   \n",
       "3165                                          negative   \n",
       "\n",
       "     ann_config_architecture_labels_truth ann_config_architecture_labels_pred  \n",
       "0                                negative                            negative  \n",
       "1                                positive                            positive  \n",
       "2                                positive                            negative  \n",
       "3                                negative                            negative  \n",
       "4                                positive                            positive  \n",
       "...                                   ...                                 ...  \n",
       "3161                             negative                            negative  \n",
       "3162                             negative                            positive  \n",
       "3163                             negative                            positive  \n",
       "3164                             positive                            positive  \n",
       "3165                             positive                            positive  \n",
       "\n",
       "[3166 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.83      0.78      1409\n",
      "     neutral       0.00      0.00      0.00       167\n",
      "    positive       0.82      0.81      0.81      1590\n",
      "\n",
      "    accuracy                           0.78      3166\n",
      "   macro avg       0.52      0.55      0.53      3166\n",
      "weighted avg       0.74      0.78      0.76      3166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['ann_config_architecture_over_sampling_labels_truth'],df['ann_config_architecture_over_sampling_labels_pred'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.84      0.79      1409\n",
      "     neutral       0.00      0.00      0.00       167\n",
      "    positive       0.82      0.81      0.82      1590\n",
      "\n",
      "    accuracy                           0.78      3166\n",
      "   macro avg       0.52      0.55      0.54      3166\n",
      "weighted avg       0.74      0.78      0.76      3166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AnacondaPackage\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['ann_config_architecture_labels_truth'],df['ann_config_architecture_labels_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe4737cf0a41cf5e93c7bf4b9dc2d43d3c69fc85d82c68e3039db569ea2744e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
